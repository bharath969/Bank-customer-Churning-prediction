# -*- coding: utf-8 -*-
"""bank_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B838qE0fnZJJ44S6RCMhaZkDu8LuvgLP

# **Bank** **Classification** **using** **ANN** **bold text**:

To find out whether a customer leaves a bank or not â˜¹

### Create the environment
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder
from sklearn.model_selection import train_test_split

import pickle

"""### Upload the dataset to the drive"""

# If not uploaded to drive ,do this
from google.colab import files
uploaded = files.upload()

"""### Load The Dataset"""

data=pd.read_csv("Churn_Modelling.csv")

data.head()

data.info(0)

"""### Visualization"""

data["CreditScore"].hist(bins=30,figsize=(4,3),color="orange")
plt.xlabel("Credit Score")
plt.title(" Credict Card Score normnal distribuiton ")

data["Age"].hist(bins=30,figsize=(4,3),color="lightblue")
plt.xlabel("Age")
plt.title(" Age normnal distribuiton ")

plt.figure(figsize=(4,4))
sns.countplot(data=data,x="Gender",palette="Set2",width=0.3);

plt.title(" Genderwise Count ")

plt.figure(figsize=(6,4))
sns.countplot(data=data,x="HasCrCard",hue="Gender",palette="Set2",width=0.3)

plt.legend()
plt.title(" Number of people who has card ")

plt.figure(figsize=(8,4))
sns.countplot(data=data,x="IsActiveMember",hue="Gender",palette="Set2",width=0.3)

plt.legend()
plt.title(" Active Number of people")

plt.figure(figsize=(8,4))
sns.countplot(data=data,x="Geography",palette="Set2",width=0.3)
plt.legend()
plt.title("Number of customers per location")

"""### Drop unnecessary columns

we dont need columns RowNumber,CustomerId,Surname
"""

data=data.drop(["RowNumber","CustomerId","Surname"],axis=1)

data.head()

"""### Encoding Categorical Varialbels

Converting Geography and Gender categorical values to numerical

"""

le=LabelEncoder()

data["Gender"]=le.fit_transform(data["Gender"])

one_hot=OneHotEncoder()
geography_encoded=one_hot.fit_transform(data[["Geography"]]).toarray()
geography_encoded

colums=one_hot.get_feature_names_out(["Geography"])
colums

# converting this into dataframe
geography_encoded=pd.DataFrame(geography_encoded,columns=colums)
geography_encoded.head()

# Merge Data and Geography encoded
data=pd.concat([data.drop(["Geography",],axis=1),geography_encoded],axis=1)

data.head()

"""### Save the encoders"""

with open("label_encoder_gender.pkl","wb") as f:
  pickle.dump(le,f)

with open("onehot_encoder_geography.pkl","wb") as f:
  pickle.dump(one_hot,f)

"""### Splitting the data into X and Y"""

X=data.drop(["Exited"],axis=1)
y=data["Exited"]

X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=42)

"""### Scaling using Standard scalar"""

scaler=StandardScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)

with open("scaler.pkl","wb") as f:
  pickle.dump(scaler,f)

"""### ANN"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Input

X_train.shape,X_test.shape,y_train.shape,y_test.shape

import tensorflow as tf
from tensorflow.keras.models import Sequential     # Sequential= [forward+backward] propagation
from tensorflow.keras.layers import Dense,Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.activations import sigmoid,relu
import datetime

# Create a model
def ann_model(x):
    model=Sequential()
    model.add(Input(shape=(x.shape[1],)))
    model.add(Dense(units=64,activation=relu))
    model.add(Dense(units=32,activation=relu))
    model.add(Dense(1,activation=sigmoid))

    return model

model=ann_model(X_train)

model.summary()

# Complie the model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=tf.keras.losses.BinaryCrossentropy(),metrics=["accuracy"])

"""### Setting up tensorboard"""

datetime.datetime.now().strftime("%d-%m-%Y %H-%M-%S")

from tensorflow.keras.callbacks import EarlyStopping,TensorBoard

log_dir="logs/fit"+datetime.datetime.now().strftime("%d-%m-%Y %H-%M-%S")
tensorflow_callbacks=TensorBoard(log_dir=log_dir,histogram_freq=1)

"""### Setting up Early Call Backs"""

from tensorflow.keras.callbacks import EarlyStopping
early_stopping_callbacks=EarlyStopping(monitor="val_loss",patience=10,restore_best_weights=True)

"""### Train the model"""

history=model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[tensorflow_callbacks,early_stopping_callbacks])

"""### Save the model"""

model.save("bank_model.keras")

"""### Load Tensorboard Extension"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/fit16-09-2024\ 16-09-52

"""### Load the model and encoders"""

from tensorflow.keras.models import load_model
# load the model
model = load_model("bank_model.keras")

# load the encoders
with open("label_encoder_gender.pkl", "rb") as f:
    le = pickle.load(f)

with open("onehot_encoder_geography.pkl", "rb") as f:
    one_hot = pickle.load(f)

# load the scaler
with open("scaler.pkl", "rb") as f:
    scaler = pickle.load(f)



"""### Prediction"""

input_data={'CreditScore':600,
            'Geography':'France',
            'Gender':'Male',
            'Age':40,
            'Tenure':3,
            'Balance':60000,
            'NumOfProducts':2,
            'HasCrCard':1,
            'IsActiveMember':1,
            'EstimatedSalary':50000 }

# convert the above for input into the model
def modify_input(input_data):

    # creating the dataframe
    input_df=pd.DataFrame(input_data,index=[0])

    # label encoding the gender
    input_df["Gender"]=le.transform(input_df["Gender"])

    # One hot encoding the geography and converting them into np arary
    one_hot_input=one_hot.transform(input_df[["Geography"]]).toarray()

    # Create datframe
    one_hot_input=pd.DataFrame(one_hot_input,columns=one_hot.get_feature_names_out(["Geography"]))

    # concat both dfs and removing geography columnn
    input_df=pd.concat([input_df.drop(["Geography",],axis=1),one_hot_input],axis=1)

    # scaling up the data
    input_df=scaler.transform(input_df)

    return input_df

input_df=modify_input(input_data)
input_df

"""### ***Predictions***"""



#prediction
pred_probabilty=model.predict(input_df)
pred_probabilty

pred_probabilty=pred_probabilty[0][0]
pred_probabilty

if pred_probabilty>0.5:
    print("Customer will leave the bank")
else:
    print("Customer will not leave the bank")



